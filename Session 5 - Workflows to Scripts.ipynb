{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24b208aa",
   "metadata": {},
   "source": [
    "# Session 5- Batch Analysis\n",
    "*Goal - learn how to use the QuPath-created workflow to apply your analysis pipeline to multiple images*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ef653b",
   "metadata": {},
   "source": [
    "## 1. Generating the Raw Workflow  Script\n",
    "1. To repeat the analysis we've performed so far on a new image, we need to reproduce a few major steps:\n",
    "  1. Segment the tissue with the \"Tissue\" pixel classifier\n",
    "  2. Detect cells\n",
    "  3. Segment the cancer with the \"Tumor\" pixel classifier\n",
    "\n",
    "  This is different from the order we originally performed the steps in. Creating the Tumor object *after* cell detection will prevent it from being deleted. \n",
    "<br>\n",
    "  \n",
    "2. Start with LungImg2 open (the version with InstanSeg cell detections)\n",
    "3. Open the Workflow tab. It will have a long list of commands that you have tried. \n",
    "\n",
    "  <img src=\"Images/WorkflowTab.PNG\"> <br>\n",
    "\n",
    "  **Don't be scared!** It looks overwhelming, but it just a list of buttons you've pressed. <br>\n",
    "\n",
    "4. At the bottom of the screen, click <kbd>Create workflow</kbd> \n",
    "\n",
    "5. You'll get a window with a list of commands you've run. We're going to simplify that list by deleting anything unnecessary for analyzing the other images in the project. Therefore, delete (`highlight > right click > remove selected items`):\n",
    "  - All of the duplicates of \"Set image type\" , leaving only 1 copy \n",
    "  - All of the \"Cell detection\" lines that ran the built-in cell detection, because we are going to use InstanSeg \n",
    "  - All of the \"Delete selected objects\" or \"Clear detections\" commands, because they are only useful during optimization. \n",
    "  - All but the last \"Run InstanSeg model\" command\n",
    "    <img src=\"Images/DeleteWorkflowCommands.gif\">\n",
    "  \n",
    "6. This will leave you with a much shorter list of steps, though it still needs further editing.  Click `Create script` at the bottom.\n",
    "7. Expand the Script Editor window to make it easier to read. It will look something like this (your exact script will be different).\n",
    "\n",
    "<img src=\"Images/ScriptEx1.PNG\"> <br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "421df45c",
   "metadata": {},
   "source": [
    "## 2. Editing the Script to do what we want\n",
    "From here, we need to remove some extraneous lines and rearrange others. Step-by-step, here is what we need the script to do:\n",
    "\n",
    "1. Set Image Type (`setImageType('FLUORESCENCE');`) - this declares that this is a fluorescence image with multiple channels. \n",
    "2. Segment the whole tissue. This will be one of the lines that starts `createAnnotationsFromPixelClassifier`. You will have a few of those in your starting script- find the one that uses the Tissue classifier and has the correct size parameters. Copy-paste it to be the second line in the script. \n",
    "\n",
    "    <img src=\"Images/ScriptLine2.gif\">\n",
    "    <br><br>\n",
    "    \n",
    "3. We need to select the annotation we just made before detecting cells. We can do that with the command `selectObjectsByClassification(\"Region*\");` which selects all objects with the Region* class.  Copy-paste that to be the third line in the script.  \n",
    "\n",
    "4. Then, we segment the cells in the whole tissue. The InstanSeg function to do this is multiple lines, starting with `qupath.ext.instanseg.core.InstanSeg.builder()` and ending with an indented line `    .detectObjects()`. Copy-paste that ENTIRE section to be the next part of the the code. \n",
    "\n",
    "  <img src=\"Images/InstanSegScriptLIne2.gif\">\n",
    "    \n",
    "    \n",
    "\n",
    "4. Last, we create the tumor annotation. This was also done with the function `createAnnotationsFromPixelClassifier`, but this time look for the one that says \"TumorPixelClassifier\" (or whatever you named your classifier).  Copy-paste that to be line 4.  Your parameters may look different than mine.\n",
    "\n",
    "  <img src=\"Images/Script_TumorLine.PNG\"> <br>\n",
    "\n",
    " \n",
    "6. Delete all other lines after the `createAnnotationsFromPixelClassifier(\"TumorPixelClassifier\", 500.0, 500.0)`\n",
    "<br>\n",
    "\n",
    "7. Save the script! In the Script Editor window, `File > Save As`. This will generate a Scripts folder inside your project folder. Give it a meaningful name. \n",
    "\n",
    "    <img src=\"Images/ScriptingSaveAs.PNG\">\n",
    "\n",
    "8. My finished script looks like this (below). If you need to, you can copy-paste it. However *You must change the path in line 6* to the location where QuPath downloaded the model on your computer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7214b76",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (Temp/ipykernel_38064/3319901584.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\smcardle\\AppData\\Local\\Temp/ipykernel_38064/3319901584.py\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    .modelPath(\"C:/Users/smcardle/Documents/InstanSeg Models/fluorescence_nuclei_and_cells\")\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "setImageType('FLUORESCENCE');\n",
    "createAnnotationsFromPixelClassifier(\"Tissue\", 1000.0, 1000.0, \"INCLUDE_IGNORED\")\n",
    "selectObjectsByClassification(\"Region*\");\n",
    "qupath.ext.instanseg.core.InstanSeg.builder()\n",
    "    .modelPath(\"C:/Users/smcardle/Documents/InstanSeg Models/fluorescence_nuclei_and_cells\")\n",
    "    .device(\"cpu\")\n",
    "    .inputChannels([ColorTransforms.createChannelExtractor(\"Hoechst\"), ColorTransforms.createChannelExtractor(\"CD11c\"), ColorTransforms.createChannelExtractor(\"CD68\"), ColorTransforms.createChannelExtractor(\"CD163\"), ColorTransforms.createChannelExtractor(\"CD20\"), ColorTransforms.createChannelExtractor(\"CD4\"), ColorTransforms.createChannelExtractor(\"CD8a\"), ColorTransforms.createChannelExtractor(\"CD45RO\"), ColorTransforms.createChannelExtractor(\"PD1\"), ColorTransforms.createChannelExtractor(\"CD45\"), ColorTransforms.createChannelExtractor(\"S100a\")])\n",
    "    .outputChannels()\n",
    "    .tileDims(512)\n",
    "    .interTilePadding(16)\n",
    "    .nThreads(4)\n",
    "    .makeMeasurements(false)\n",
    "    .randomColors(false)\n",
    "    .build()\n",
    "    .detectObjects()\n",
    "createAnnotationsFromPixelClassifier(\"TumorPixelClassifier\", 500.0, 500.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15616aa8",
   "metadata": {},
   "source": [
    "\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
