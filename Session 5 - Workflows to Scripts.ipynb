{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24b208aa",
   "metadata": {},
   "source": [
    "# Session 5- Batch Analysis\n",
    "*Goal - learn how to use the QuPath-created workflow to apply your analysis pipeline to multiple images*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ef653b",
   "metadata": {},
   "source": [
    "## 1. Generating the Raw Workflow  Script\n",
    "1. To repeat the analysis we've performed so far on a new image, we need to reproduce a few major steps:\n",
    "  1. Segment the tissue with the \"Tissue\" pixel classifier\n",
    "  2. Segment the cancer with the \"Tumor\" pixel classifier\n",
    "  3. Detect cells\n",
    "  \n",
    "2. Start with LungImg2 open (the version with InstanSeg cell detections)\n",
    "3. Open the Workflow tab. It will have a long list of commands that you have tried. \n",
    "\n",
    "  <img src=\"Images/WorkflowTab.PNG\"> <br>\n",
    "\n",
    "  **Don't be scared!** It looks overwhelming, but it just a list of buttons you've pressed. <br>\n",
    "\n",
    "4. At the bottom of the screen, click <kbd>Create workflow</kbd> \n",
    "\n",
    "5. You'll get a window with a list of commands you've run. We're going to simplify that list by deleting anything unnecessary for analyzing the other images in the project. Therefore, delete (`highlight > right click > remove selected items`):\n",
    "  - All of the duplicates of \"Set image type\" , leaving only 1 copy \n",
    "  - All of the \"Cell detection\" lines that ran the built-in cell detection, because we are going to use InstanSeg \n",
    "  - All of the \"Delete selected objects\" or \"Clear detections\" commands, because they are only useful during optimization. \n",
    "  - All but the last \"Run InstanSeg model\" command\n",
    "    <img src=\"Images/DeleteWorkflowCommands.gif\">\n",
    "  \n",
    "6. This will leave you with a much shorter list of steps, though it might be out of order.  Click `Create script` at the bottom.\n",
    "7. Expand the Script Editor window to make it easier to read. It will look something like this (your exact script will be different).\n",
    "\n",
    "<img src=\"Images/ScriptEx1.PNG\"> <br>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18fa66f",
   "metadata": {},
   "source": [
    "## 2. Editing the Script to do what we want\n",
    "From here, we need to remove some extraneous lines and rearrange others. Step-by-step, here is what we need the script to do:\n",
    "\n",
    "1. Set Image Type (`setImageType('FLUORESCENCE');`) - this declares that this is a fluorescence image with multiple channels. \n",
    "2. Segment the whole tissue. This will be one of the lines that starts `createAnnotationsFromPixelClassifier`. You will have a few of those in your starting script- find the one that uses the Tissue classifier and has the correct size parameters. Copy-paste it to be the second line in the script. \n",
    "\n",
    "    <img src=\"Images/ScriptLine2.gif\">\n",
    "    \n",
    "3. After creating the tissue annotation, we need to select it before we create the tumor annotation. We can do that with the command `selectObjectsByClassification(\"Region*\");` which selects all objects with the Region* class.  Copy-paste that to be the third line in the script.  \n",
    "\n",
    "4. Then, we create the tumor annotation. This was also done with the function `createAnnotationsFromPixelClassifier`, but this time look for the one that says \"TumorPixelClassifier\" (or whatever you named your classifier).  Copy-paste that to be line 4. \n",
    "\n",
    "<img src=\"Images/Script1_line4.PNG\"> <br>\n",
    "\n",
    "5. Last, we segment the cells in the whole tissue. The InstanSeg function to do this is multiple lines, starting with `qupath.ext.instanseg.core.InstanSeg.builder()` and ending with an indented line `    .detectObjects()`. Copy-paste that ENTIRE section to be the next part of the the code. \n",
    "\n",
    "    <img src=\"Images/InstanSegScriptLine.gif\">\n",
    "\n",
    "\n",
    "6. **IMPORTANT NOTE FOR WINDOWS USERS** There is a very small bug that generates the model path incorrectly on Windows systems. You must edit the path by adding additional backslashes at every folder name. See here: \n",
    "\n",
    "    <img src=\"Images/Backslashes.gif\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
